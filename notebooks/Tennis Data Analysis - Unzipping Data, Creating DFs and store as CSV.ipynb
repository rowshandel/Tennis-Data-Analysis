{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Unzip the main folder to the target directory\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(file_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mzip_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1744\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1741\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1802\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[0;32m   1801\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[1;32m-> 1802\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:203\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    201\u001b[0m fsrc_read \u001b[38;5;241m=\u001b[39m fsrc\u001b[38;5;241m.\u001b[39mread\n\u001b[0;32m    202\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m buf \u001b[38;5;241m:=\u001b[39m \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    204\u001b[0m     fdst_write(buf)\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:989\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 989\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1079\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1079\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\SilkRoadit.com\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1004\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[1;34m(self, newdata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1004\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to the main directory where the zip file is located\n",
    "main_zip_path = r\"E:\\Data Analysis Course\\Data analyse\\Data Analyse final project\"\n",
    "file_name = '202405.zip'\n",
    "file_path = os.path.join (main_zip_path, file_name)\n",
    "\n",
    "# Path to the target extraction directory\n",
    "extract_to = r\"E:\\Data Analysis Course\\Data analyse\\Data Analyse final project\\extracted\"\n",
    "\n",
    "# Ensure the target extraction directory exists\n",
    "os.makedirs(extract_to, exist_ok=True)\n",
    "\n",
    "# Unzip the main folder to the target directory\n",
    "with zipfile.ZipFile(file_path,'r') as zip_ref:\n",
    "    zip_ref.extractall (extract_to)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, list the directories inside the extracted folder\n",
    "extracted_files = os.listdir(extract_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, list the directories inside the extracted folder\n",
    "extracted_files = os.listdir(extract_to)\n",
    "# Loop through each extracted file to unzip its contents if they are zip files\n",
    "for file in extracted_files:\n",
    "    file_path = os.path.join(extract_to, file)\n",
    "    if zipfile.is_zipfile(file_path):\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            # Extract each zip file to a directory named after the zip file (without the .zip extension)\n",
    "            sub_extract_path = os.path.join(extract_to, file.replace('.zip', ''))\n",
    "            os.makedirs(sub_extract_path, exist_ok=True)\n",
    "            zip_ref.extractall(sub_extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SilkRoadit.com\\AppData\\Local\\Temp\\ipykernel_39240\\3982440912.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_dfs = {schema: pd.concat(dfs, ignore_index=True) for schema, dfs in schema_dfs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchAwayTeamInfo DataFrame Shape: (12955, 18)\n",
      "MatchAwayScoreInfo DataFrame Shape: (19676, 14)\n",
      "MatchEventInfo DataFrame Shape: (19676, 10)\n",
      "MatchHomeTeamInfo DataFrame Shape: (14090, 18)\n",
      "MatchHomeScoreInfo DataFrame Shape: (19676, 14)\n",
      "MatchRoundInfo DataFrame Shape: (12087, 5)\n",
      "MatchSeasonInfo DataFrame Shape: (19676, 4)\n",
      "MatchTimeInfo DataFrame Shape: (19676, 7)\n",
      "MatchTournamentInfo DataFrame Shape: (19676, 16)\n",
      "MatchVenueInfo DataFrame Shape: (19589, 5)\n",
      "OddsInfo DataFrame Shape: (33740, 11)\n",
      "GameInfo DataFrame Shape: (1467013, 13)\n",
      "PeriodInfo DataFrame Shape: (794368, 13)\n",
      "PowerInfo DataFrame Shape: (269694, 5)\n",
      "MatchVotesInfo DataFrame Shape: (19677, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold DataFrames for each schema\n",
    "schema_dfs = {}\n",
    "\n",
    "# Traverse the directories to find Parquet files and assign them to appropriate schemas\n",
    "\n",
    "# 1- finding parquet files and creating file_path for each parquet file:\n",
    "for root, dirs, files in os.walk(extract_to):\n",
    "    for file in files:\n",
    "        if file.endswith('.parquet'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            schema_name = None\n",
    "            # 2- Determine schema based on the file name\n",
    "            if file.startswith('away_team_1'):\n",
    "                schema_name = 'MatchAwayTeamInfo'\n",
    "            elif file.startswith('away_team_score'):\n",
    "                schema_name = 'MatchAwayScoreInfo'\n",
    "            elif file.startswith('event'):\n",
    "                schema_name = 'MatchEventInfo'\n",
    "            elif file.startswith('home_team_1'):\n",
    "                schema_name = 'MatchHomeTeamInfo'\n",
    "            elif file.startswith('home_team_score'):\n",
    "                schema_name = 'MatchHomeScoreInfo'\n",
    "            elif file.startswith('round'):\n",
    "                schema_name = 'MatchRoundInfo'\n",
    "            elif file.startswith('season'):\n",
    "                schema_name = 'MatchSeasonInfo'\n",
    "            elif file.startswith('time'):\n",
    "                schema_name = 'MatchTimeInfo'\n",
    "            elif file.startswith('tournament'):\n",
    "                schema_name = 'MatchTournamentInfo'\n",
    "            elif file.startswith('venue'):\n",
    "                schema_name = 'MatchVenueInfo'\n",
    "            elif file.startswith('odds'):\n",
    "                schema_name = 'OddsInfo'\n",
    "            elif file.startswith('pbp'):\n",
    "                schema_name = 'GameInfo'\n",
    "            elif file.startswith('statistics'):\n",
    "                schema_name = 'PeriodInfo'\n",
    "            elif file.startswith('power'):\n",
    "                schema_name = 'PowerInfo'\n",
    "            elif file.startswith('votes'):\n",
    "                schema_name = 'MatchVotesInfo'\n",
    "\n",
    "            # If schema is identified, add the file to the corresponding DataFrame list\n",
    "\n",
    "            # 3- Creating a list of schema names named schema_dfs\n",
    "            if schema_name:\n",
    "                if schema_name not in schema_dfs:\n",
    "                    schema_dfs[schema_name] = []\n",
    "            # 4- reading each parquet file with file_path and putting in dataframe named df\n",
    "                df = pd.read_parquet(file_path)\n",
    "            # 5- Creating the schema_dfs dictionary which keys are schema_names and values are dfs\n",
    "                schema_dfs[schema_name].append(df)\n",
    "\n",
    "# 6- Concatenate DataFrames for each schema\n",
    "final_dfs = {schema: pd.concat(dfs, ignore_index=True) for schema, dfs in schema_dfs.items()}\n",
    "\n",
    "# 7- Display final DataFrames\n",
    "for schema, df in final_dfs.items():\n",
    "    \n",
    "    print(f\"{schema} DataFrame Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatchAwayTeamInfo = final_dfs ['MatchAwayTeamInfo']\n",
    "MatchAwayScoreInfo = final_dfs ['MatchAwayScoreInfo']\n",
    "MatchEventInfo = final_dfs ['MatchEventInfo']\n",
    "MatchHomeTeamInfo = final_dfs ['MatchHomeTeamInfo']\n",
    "MatchHomeScoreInfo = final_dfs ['MatchHomeScoreInfo']\n",
    "MatchRoundInfo = final_dfs ['MatchRoundInfo']\n",
    "MatchSeasonInfo = final_dfs ['MatchSeasonInfo'] \n",
    "MatchTimeInfo = final_dfs ['MatchTimeInfo']\n",
    "MatchTournamentInfo = final_dfs ['MatchTournamentInfo']\n",
    "MatchVenueInfo = final_dfs ['MatchVenueInfo']\n",
    "OddsInfo = final_dfs['OddsInfo']\n",
    "GameInfo = final_dfs ['GameInfo']\n",
    "PeriodInfo = final_dfs ['PeriodInfo']\n",
    "PowerInfo = final_dfs ['PowerInfo']\n",
    "MatchVotesInfo = final_dfs ['MatchVotesInfo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatchAwayScoreInfo.to_csv ('MatchAwayTeamInfo.csv', index=False)\n",
    "MatchAwayScoreInfo.to_csv ('MatchAwayScoreInfo.csv', index=False)\n",
    "MatchEventInfo.to_csv ('MatchEventInfo.csv', index=False)\n",
    "MatchHomeTeamInfo.to_csv ('MatchHomeTeamInfo.csv', index=False)\n",
    "MatchHomeScoreInfo.to_csv ('MatchHomeScoreInfo.csv', index=False)\n",
    "MatchRoundInfo.to_csv ('MatchRoundInfo.csv', index=False)\n",
    "MatchSeasonInfo.to_csv ('MatchSeasonInfo.csv', index=False)\n",
    "MatchTimeInfo.to_csv ('MatchTimeInfo.csv', index=False)\n",
    "MatchTournamentInfo.to_csv ('MatchTournamentInfo.csv', index=False)\n",
    "MatchVenueInfo.to_csv ('MatchVenueInfo.csv', index=False)\n",
    "OddsInfo.to_csv ('OddsInfo.csv', index=False)\n",
    "GameInfo.to_csv ('GameInfo.csv', index=False)\n",
    "PeriodInfo.to_csv ('PeriodInfo.csv', index=False)\n",
    "PowerInfo.to_csv ('PowerInfo.csv', index=False)\n",
    "MatchVotesInfo.to_csv ('MatchVotesInfo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
